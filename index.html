<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Raspberry Pi GoPiGo Robot EKF SLAM : Project Details">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Raspberry Pi GoPiGo Robot EKF SLAM</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/gopalmenon/Raspberri-Pi-GoPiGo-Robot-EKF-SLAM-Manuscript">View on GitHub</a>

          <h1 id="project_title">Raspberry Pi GoPiGo Robot EKF SLAM</h1>
          <h2 id="project_tagline">Project Details</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/gopalmenon/Raspberri-Pi-GoPiGo-Robot-EKF-SLAM-Manuscript/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/gopalmenon/Raspberri-Pi-GoPiGo-Robot-EKF-SLAM-Manuscript/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h3>
<a id="Abstract" class="anchor" href="#Abstract" aria-hidden="true"><span class="octicon octicon-link"></span></a>Abstract</h3>

<p>This is an implementation of Extended Kalman Filter (EKF) Simultaneous Localization and Mapping (SLAM ) using a Raspberry Pi based GoPiGo robot that is sold by <a href="http://www.dexterindustries.com">Dexter Industries</a> in kit form. The robot has two powered wheels and a third castor wheel. It is equipped with an ultrasonic range finder that is mounted on a servo mechanism that allows for the range finder to be pointed in any direction in front of the robot.  An EKF SLAM implementation consists of two steps - prediction and updation. The prediction step has been implemented successfully. However, the updation step has not been fully implemented due to problems with the ultrasonic sensor as described below in the <a href="#ImplementationDetails">implementation details</a>.</p>

<img src="images/gopigo_kit_web.jpg" alt="GoPiGo Robot"/>

<h3>

<a id="ProblemDescription" class="anchor" href="#ProblemDescription" aria-hidden="true"><span class="octicon octicon-link"></span></a>Problem Description</h3>

<p>Robot motion is stochastic and not deterministic. A robot does not faithfully execute movement commands due to inaccuracies in its motion mechanism, approximations made in modeling its environment and incomplete modeling of the physics of its operating environment. Due to these reasons, the robot may not end up exactly at the location where it should have been if the movement command had been faithfully executed. The robot position may be thought of as a two dimensional probability distribution. This probability distribution will have a mean that will be equal to the expected robot location based on the movement command. The covariance will be the measure of how faithfully it executes commands. Due to this uncertainty in movement, with each motion command, the location uncertainty increases and after a while the robot gets lost.</p>

<table style="border-collapse: collapse;">
  <caption align="bottom">
    Sampling approximation of the position belief for a non-sensing robot. The solid line displays the actions, and the samples represent the robot’s belief at different points in time.
  </caption>
  <tr>
    <td>
      <img src="images/LostRobot.png" alt="Position belief of non-sensing robot"/>
    </td>
  </tr>
</table>

<p>
  In the above diagram, before the robot starts moving, it knows exactly where it is. So it's location belief is a single point. After each movement, its location uncertainty increases. This is shown by the location probability distribution that changes from a point to a larger area with each step. In the final position of the robot, the uncertainty is the largest as it accumulates the added uncertainty with each step.
</p>
<p>In some applications, robots need to be able to go into an unknown environment and explore it. This is a difficult problem due to the issue described above. If a map of the environment is available, the robot can use sensors to find its location in the environment. Conversely, if the robot knows where it is, it can generate an environment map. This is a sort of chicken and end problem. Simultaneous Localization and Mapping (SLAM) solves this problem. An Extended Kalman Filter (EKF) can be used to reduce robot location uncertainty. This page describes the implementation of EKF SLAM using a robot. The EKF SLAM implementation enables the robot to keep track of its location within an environment and also create a map of the environment as it is moving.</p>

<h3>
<a id="WhatIsAKalmanFilter" class="anchor" href="#WhatIsAKalmanFilter" aria-hidden="true"><span class="octicon octicon-link"></span></a>What is a Kalman Filter</h3>

<p>As it moves through an environment, the robot uses the knowledge of its own movement and sensing uncertainties in conjunction with an EKF to reduce its location uncertainty.</p>

<table style="border-collapse: collapse;">
  <caption align="bottom">
    Cannonball flight smoothed out by a Kalman filter.
  </caption>
  <tr>
    <td>
      <img src="images/kalman2.png" alt="Kalman filter visualization" style="width:600px;height:600px;"/>
    </td>
  </tr>
</table>

Shown above is an example of the use of a Kalman filter to reduce uncertainty. A cannonball is tracked using a range-finder which returns the location with some added noise. A Kalman filter can be used to combime the expected cannonball trajectory with its location returned by a range finder to produce an good estimate of its location.

<table style="border-collapse: collapse;">
  <caption align="bottom">
    Illustration of Kalman filters: (a) initial belief, (b) a measurement (in bold) with the associated uncertainty, (c) belief after integrating the measurement into the belief using the Kalman filter algorithm, (d) belief after motion to the right (which introduces uncertainty), (e) a new measurement with associated uncertainty, and (f) the resulting belief.
  </caption>
  <tr>
    <td>
      <img src="images/LocationProb.png" alt="Kalman filter used for reducing uncertainty" style="width:600px;height:600px;"/>
    </td>
  </tr>
</table>
  
<p>
  The above figure illustrates the Kalman filter for a simplistic one-dimensional localization scenario. Suppose the robot moves in the horizontal axis in each diagram with the prior over the robot localization given by the normal distribution shown in 1a. The robot queries its sensors on its location and these return a measurement that is centered at the peak of the bold Gaussian distribution in 1b. The peak corresponds to the value returned by the sensors and the its width or variance corresponds to the uncertainty in measurement. Combining the prior with the measurement yields the bold Gaussian in 1c. The belief’s mean lies between the two original means, and its uncertainty width is smaller than both contributing Gaussians. The is the result of the information gain from using the Kalman filter. Now lets assume that the robot moves towards the right. Its uncertainty grows due to the fact that the state transition is stochastic. This results in the the Gaussian shown in bold in 1d. This Gaussian is shifted by the amount the robot moved and is also wider because of the uncertainty introduced by the movement. The robot does a second sensor measurement shown in 1e, which results in the posterior shown in 1f.
</p>  

<table style="border-collapse: collapse;">
  <caption align="bottom">
    Linear transformation of a Gaussian random variable. The lower right plot shows the density of the original random variable, X. This random variable is passed through the function displayed in the upper right graph (the transformation of the mean is indicated by the dotted line). The density of the resulting random variable Y is plotted in the upper left graphs.
  </caption>
  <tr>
    <td>
      <img src="images/LinearXform.png" alt="Linear transform" style="width:600px;height:600px;"/>
    </td>
  </tr>
</table>

<p>
  Shown above in the bottom-right part is a prior Gaussian probability distribution for a robot location and the posterior distribution on the upper-left part after it is acted on by a linear transformation. The posterior distribution is also Gaussian. In such cases a Kalman filter can be used for reducing uncertainty.
</p>


<table style="border-collapse: collapse;">
  <caption align="bottom">
    Illustration of linearization applied by the EKF. Instead of passing the Gaussian through the nonlinear function g, it is passed through a linear approximation of g. The linear function is tangent to g at the mean of the original Gaussian. The resulting Gaussian is shown as the dashed line in the upper left graph.
  </caption>
  <tr>
    <td>
      <img src="images/NonLinearXform.png" alt="Non-Linear filter transform" style="width:600px;height:600px;"/>
    </td>
  </tr>
</table>

<p>
  Shown above in the bottom-right part is a prior Gaussian probability distribution for a robot location and the shaded posterior distribution on the upper-left part after it is acted on by a non-linear transformation. The posterior distribution is not Gaussian. In such cases a Kalman filter cannot be used for reducing uncertainty. An extended Kalman filter can be employed by making use of a tangent to the non-linear function. The resulting Gaussian distribution is shown by the dotted line.
</p>

<h3>
<a id="EKFSLAMAlgorithmDetails" class="anchor" href="#EKFSLAMAlgorithmDetails" aria-hidden="true"><span class="octicon octicon-link"></span></a>EKF SLAM Algorithm Details</h3>

<table style="border-collapse: collapse;">
  <caption align="bottom">
    A graphical model of the SLAM algorithm.
  </caption>
  <tr>
    <td>
      <img src="images/GraphicalSlam.png" alt="A graphical model of the SLAM algorithm" style="width:600px;height:500px;"/>
    </td>
  </tr>
</table>
<p>
   A graphical model of the SLAM algorithm is shown above. The robot pose (X coordinate, Y coordinate and robor orientation) is depicted by the circles containing the x with subscript. The circles with u and a subscript stand for the motion command at the location. The cicle with m stands for a landmark and the circles with z and subscript stand for sensor measurements of the landmarks taken at the robot pose that it is attached to.
</p>

<table style="border-collapse: collapse;">
  <caption align="bottom">
    The essential SLAM problem. A simultaneous estimate of both robot and landmark locations is required. The true locations are never known or measured directly. Observations are made between true robot and landmark locations.
  </caption>
  <tr>
    <td>
      <img src="images/EssSlam.png" alt="Essential SLAM problem" style="width:600px;height:600px;"/>
    </td>
  </tr>
</table>
<p>
  The figure above shows a robot moving through an environment, taking measurements of landmarks. As the robot does this, the estimates of the landmarks are all correlated with each other because of the common error in estimate robot location. 
</p>


<table style="border-collapse: collapse;">
  <caption align="bottom">
    Spring network analogy. The landmarks are connected by springs describing correlations between landmarks. As the vehicle moves back and forth through the environment, spring stiffness or correlations increase (red links become thicker). As landmarks are observed and estimated locations are corrected, these changes are propagated through the spring network. Note, the robot itself is correlated to the map.
  </caption>
  <tr>
    <td>
      <img src="images/SpringSlam.png" alt="Spring network analogy" style="width:600px;height:600px;"/>
    </td>
  </tr>
</table>
<p>
  The uncertainty reduction process can be visualized as shown above as a network of springs connecting all landmarks together or as a rubber sheet in which all landmarks are embedded. An observation in a neighborhood acts like a displacement to a spring system or rubber sheet such that its effect is great in the neighborhood and, dependent on local stiffness (correlation) properties, diminishes with distance to other landmarks. As the robot moves through this environment and takes observations of the landmarks, the springs become increasingly (and monotonically) stiffer. In the limit, a rigid map of landmarks or an accurate relative map of the environment is obtained. As the map is built, the location accuracy of the robot measured relative to the map is bounded only by the quality of the map and relative measurement sensor. In the theoretical limit, robot relative location accuracy becomes equal to the localization accuracy achievable with a given map.
</p>

<h3>
<a id="ImplementationDetails" class="anchor" href="#ImplementationDetails" aria-hidden="true"><span class="octicon octicon-link"></span></a>Implementation Details</h3>

<p>
  Here are the implementation details.
</p>

<h3>
<a id="ProjectDemo" class="anchor" href="#ProjectDemo" aria-hidden="true"><span class="octicon octicon-link"></span></a>Project Demo</h3>

<iframe src="https://player.vimeo.com/video/144304966" width="500" height="281" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe> <p><a href="https://vimeo.com/144304966">GoPiGi Obstacles Navigation</a> from <a href="https://vimeo.com/user45414333">Gopal Menon</a> on <a href="https://vimeo.com">Vimeo</a>.</p>

<h3>
<a id="References" class="anchor" href="#References" aria-hidden="true"><span class="octicon octicon-link"></span></a>References</h3>

<p>[1] GoPiGo - Dexter Industries. Dexter Industries. N.p., n.d. Web. 06 Nov. 2015. http://www.dexterindustries.com/gopigo/.</p>
<p>[2] Durrant-Whyte, H., and T. Bailey, Simultaneous Localization and Map- ping: Part I, IEEE Robotics and Automation Magazine. 13.2 (2006): 99-110.</p>
<p>[3] Bailey, Tim, and Hugh Durrant-Whyte, Simultaneous localization and mapping (SLAM): Part II, IEEE Robotics and Automation Magazine. 13.3 (2006): 108-117.</p>
<p>[4] Thrun, Sebastian, Wolfram Burgard, and Dieter Fox, Probabilistic Robotics, MIT press, 2005.</p>
<p>[5] Stachniss, Cyrill, SLAM Course - WS13/14, YouTube. YouTube, n.d. Web. 18 Sept. 2015. https://www.youtube.com/playlist?list= PLgnQpQtFTOGQrZ4O5QzbIHgl3b1JHimN_.</p>

      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Raspberry Pi GoPiGo Robot EKF SLAM maintained by <a href="https://github.com/gopalmenon">gopalmenon</a></p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
